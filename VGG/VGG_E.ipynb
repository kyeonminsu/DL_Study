{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be6c77b0",
   "metadata": {},
   "source": [
    "# library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a500f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "from torchmetrics import functional as FM\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dea3107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://wikidocs.net/73569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3debc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df2fc0c",
   "metadata": {},
   "source": [
    "# 정답 csv load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994e053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_csv_path = 'Datasets/kid_f_train.csv'\n",
    "label_data = pd.read_csv(label_csv_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234e9c57",
   "metadata": {},
   "source": [
    "# class 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46481fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이름 :  ['yujin' 'wonyoung' 'rei' 'choiyena' 'kimminju' 'joyuri' 'kanghyewon'\n",
      " 'kwoneunbi' 'hondahitomi' 'sakura' 'kimchaewon' 'kazuha' 'huhyunjin'\n",
      " 'hongeunchae' 'oliviahye' 'choilee' 'hyuna' 'kwonsohyun' 'hani' 'hyerin'\n",
      " 'jeonghwa' 'le' 'solji' 'bora' 'dasom' 'hyolin' 'jeongyeon' 'jihyo'\n",
      " 'mina' 'momo' 'nayeon' 'sana' 'karina' 'winter' 'giselle' 'ningning'\n",
      " 'kimnamju' 'jisoo' 'jennie' 'rose' 'lisa' 'bravegirls_yuna'\n",
      " 'bravegirls_yujeong' 'minyoung' 'bravegirls_eunji' 'hwasa' 'sola' 'joy'\n",
      " 'yeri' 'sunny' 'sumin' 'seeun' 'yoon' 'chaewon' 'yeojin']\n",
      "총 개 수 :  55\n"
     ]
    }
   ],
   "source": [
    "count=label_data['name'].unique()\n",
    "print(\"이름 : \", count)\n",
    "print(\"총 개 수 : \", len(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c3ece",
   "metadata": {},
   "source": [
    "# 각 class마다 개수 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32aa2692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lisa                  1282\n",
       "rose                  1245\n",
       "jisoo                 1023\n",
       "jennie                 414\n",
       "kimminju               261\n",
       "joyuri                 257\n",
       "choiyena               135\n",
       "hondahitomi            119\n",
       "kimchaewon             119\n",
       "kanghyewon              83\n",
       "sakura                  79\n",
       "nayeon                  76\n",
       "oliviahye               72\n",
       "kwoneunbi               70\n",
       "yujin                   55\n",
       "wonyoung                50\n",
       "hongeunchae             35\n",
       "ningning                28\n",
       "karina                  25\n",
       "giselle                 23\n",
       "huhyunjin               22\n",
       "winter                  21\n",
       "kazuha                  18\n",
       "bravegirls_yuna         16\n",
       "minyoung                11\n",
       "bravegirls_yujeong       6\n",
       "hani                     6\n",
       "bravegirls_eunji         6\n",
       "jihyo                    3\n",
       "momo                     2\n",
       "hyerin                   2\n",
       "chaewon                  2\n",
       "seeun                    2\n",
       "hyuna                    2\n",
       "dasom                    1\n",
       "hwasa                    1\n",
       "sana                     1\n",
       "yoon                     1\n",
       "jeongyeon                1\n",
       "sumin                    1\n",
       "sunny                    1\n",
       "yeri                     1\n",
       "joy                      1\n",
       "sola                     1\n",
       "rei                      1\n",
       "bora                     1\n",
       "choilee                  1\n",
       "mina                     1\n",
       "kwonsohyun               1\n",
       "hyolin                   1\n",
       "jeonghwa                 1\n",
       "le                       1\n",
       "solji                    1\n",
       "kimnamju                 1\n",
       "yeojin                   1\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 블랙핑크 몰빵 -> 데이터 샘플링 or class weight 써보기\n",
    "label_data['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fbf9e5",
   "metadata": {},
   "source": [
    "# Label Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b21d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "name = le.fit_transform(label_data['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913b5f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5591,)\n"
     ]
    }
   ],
   "source": [
    "print(name.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691dfd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "print(name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9efa7227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33    1282\n",
       "41    1245\n",
       "21    1023\n",
       "17     414\n",
       "28     261\n",
       "23     257\n",
       "6      135\n",
       "10     119\n",
       "27     119\n",
       "24      83\n",
       "42      79\n",
       "37      76\n",
       "39      72\n",
       "30      70\n",
       "54      55\n",
       "50      50\n",
       "11      35\n",
       "38      28\n",
       "25      25\n",
       "8       23\n",
       "12      22\n",
       "49      21\n",
       "26      18\n",
       "3       16\n",
       "35      11\n",
       "2        6\n",
       "9        6\n",
       "1        6\n",
       "20       3\n",
       "36       2\n",
       "14       2\n",
       "4        2\n",
       "44       2\n",
       "16       2\n",
       "7        1\n",
       "13       1\n",
       "43       1\n",
       "53       1\n",
       "19       1\n",
       "47       1\n",
       "48       1\n",
       "52       1\n",
       "22       1\n",
       "45       1\n",
       "40       1\n",
       "0        1\n",
       "5        1\n",
       "34       1\n",
       "31       1\n",
       "15       1\n",
       "18       1\n",
       "32       1\n",
       "46       1\n",
       "29       1\n",
       "51       1\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'name' : name})\n",
    "df['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ac17d",
   "metadata": {},
   "source": [
    "# image load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "225b3c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 이미지 개 수 :  5591\n"
     ]
    }
   ],
   "source": [
    "img_path = 'Datasets/HQ_512x512/HQ_512x512/'\n",
    "dataset_size = len(label_data)\n",
    "train_data = np.zeros((dataset_size,224,224,3), dtype=np.float32)\n",
    "\n",
    "\n",
    "for i in range(0, dataset_size):\n",
    "    img=cv2.imread(img_path+str(label_data['file_name'][i]))\n",
    "    img_resize = cv2.resize(img, (224,224), interpolation=cv2.INTER_AREA)\n",
    "    train_data[i] = img_resize / 255\n",
    "    \n",
    "print(\"총 이미지 개 수 : \", len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee9a80",
   "metadata": {},
   "source": [
    "# 학습데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df1481bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ade076",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(train_data).float()  \n",
    "y_train_tensor = torch.from_numpy(name).type(torch.LongTensor)  \n",
    "x_train_tensor = x_train_tensor.permute(0,3,2,1).contiguous()\n",
    "total_train_data = CustomDataset(x_train_tensor, y_train_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf833442",
   "metadata": {},
   "source": [
    "# VGG19 model 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "868202a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet_E(pl.LightningModule):\n",
    "    def __init__(self, out_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Convolutional layer\n",
    "        self.cnn_layer_1 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 3,out_channels =64,kernel_size =3, stride =1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 64,out_channels =64,kernel_size =3, stride =1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.cnn_layer_2 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels =64 ,out_channels =128 ,kernel_size =3 ,stride =1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels =128 ,out_channels =128 ,kernel_size =3 ,stride =1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.cnn_layer_3 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 128, out_channels =256,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 256, out_channels =256,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 256, out_channels =256,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 256, out_channels =256,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.cnn_layer_4 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 256, out_channels =512,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels =512,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels =512,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels =512,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.cnn_layer_5 =nn.Sequential(\n",
    "            nn.Conv2d(in_channels = 512, out_channels =512,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels =512,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels =512,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels = 512, out_channels =512,kernel_size =3,stride = 1 , padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        #FC Layer\n",
    "        self.fc_layer_1=nn.Sequential(\n",
    "            nn.Linear(512*7*7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5)\n",
    "        )\n",
    "        \n",
    "        self.fc_layer_2=nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "        )\n",
    "        \n",
    "        self.fc_layer_3=nn.Sequential(\n",
    "            nn.Linear(4096, out_dim)\n",
    "            #Cross Entropy Loss에서 softmax를 포함한다.\n",
    "            #nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Convolutional layer\n",
    "        x=self.cnn_layer_1(x)\n",
    "        x=self.cnn_layer_2(x)\n",
    "        x=self.cnn_layer_3(x)\n",
    "        x=self.cnn_layer_4(x)\n",
    "        x=self.cnn_layer_5(x)\n",
    "        \n",
    "        #FC layer\n",
    "        x = x.view(-1, 512 * 7 * 7)\n",
    "        x=self.fc_layer_1(x)\n",
    "        x=self.fc_layer_2(x)\n",
    "        x=self.fc_layer_3(x)\n",
    "        \n",
    "        return x\n",
    "       \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x,y=batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        #y = y.to(torch.float32)\n",
    "        y=y.long()\n",
    "        pred_y = self(x)\n",
    "        acc = FM.accuracy(pred_y, y)\n",
    "        loss = F.cross_entropy(pred_y, y)\n",
    "        metrics = {'val_acc': acc, 'val_loss': loss}\n",
    "        self.log_dict(metrics , on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    " \n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        pred_y = self(x)\n",
    "        acc = FM.accuracy(pred_y, y)\n",
    "        loss = F.cross_entropy(pred_y, y)\n",
    "        metrics = {'test_acc': acc, 'test_loss': loss}\n",
    "        self.log_dict(metrics , on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        pass\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(),\n",
    "                              lr = 0.001)\n",
    "                    \n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "        \n",
    "        return [optimizer],[lr_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17590d62",
   "metadata": {},
   "source": [
    "# Datasets class 정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4594f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasets(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, datasets):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.datasets = datasets\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        #데이터 load 하는 부분\n",
    "        pass\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        \n",
    "        if stage == 'fit':\n",
    "            self.train_size = int(0.8 * len(self.datasets))\n",
    "            self.test_size = len(self.datasets) - self.train_size\n",
    "            self.train, self.val = random_split(self.datasets, [self.train_size, self.test_size])\n",
    "        if stage == 'test':\n",
    "            self.test = self.datasets\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch_size)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4fb6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Datasets(batch_size = 16, datasets = total_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9239515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.setup(stage='fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74651c8",
   "metadata": {},
   "source": [
    "# checkpoint 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35d0c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=\"checkpoints\",\n",
    "  filename=\"best-checkpoint\",\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "\n",
    "#early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc0a34",
   "metadata": {},
   "source": [
    "# 학습 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ded6f4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type       | Params\n",
      "-------------------------------------------\n",
      "0 | cnn_layer_1 | Sequential | 38.7 K\n",
      "1 | cnn_layer_2 | Sequential | 221 K \n",
      "2 | cnn_layer_3 | Sequential | 2.1 M \n",
      "3 | cnn_layer_4 | Sequential | 8.3 M \n",
      "4 | cnn_layer_5 | Sequential | 9.4 M \n",
      "5 | fc_layer_1  | Sequential | 102 M \n",
      "6 | fc_layer_2  | Sequential | 16.8 M\n",
      "7 | fc_layer_3  | Sequential | 225 K \n",
      "-------------------------------------------\n",
      "139 M     Trainable params\n",
      "0         Non-trainable params\n",
      "139 M     Total params\n",
      "559.182   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6193316adf54340b949d435ed55fcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 280: 'val_loss' reached 2.34869 (best 2.34869), saving model to 'D:\\\\minsu\\\\DL\\\\VGGNet\\\\checkpoints\\\\best-checkpoint-v2.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 560: 'val_loss' reached 2.34837 (best 2.34837), saving model to 'D:\\\\minsu\\\\DL\\\\VGGNet\\\\checkpoints\\\\best-checkpoint-v2.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 840: 'val_loss' reached 2.34617 (best 2.34617), saving model to 'D:\\\\minsu\\\\DL\\\\VGGNet\\\\checkpoints\\\\best-checkpoint-v2.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1120: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1400: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1680: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1960: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2240: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2520: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 2800: 'val_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "model =  VGGNet_E(out_dim = 55)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "                    accelerator='gpu',\n",
    "                    devices=1,\n",
    "                     max_epochs=10,\n",
    "                     #callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "                     callbacks=[checkpoint_callback],\n",
    "                     deterministic=True\n",
    "                    )\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd06e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"VGG_E.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
